# The Software Stack That Achieved Global Second Place at the Shell Eco-marathon APC 2025

This repository contains the complete software system developed for the **Shell Eco-marathon Autonomous Programming Competition 2025**, where it secured **global second place**. The system was implemented and tested on the **CARLA Simulator**, integrating classical perception, planning, and control methods with efficiency-optimized behavior planning.  

---

## ğŸ† Competition Objective  
The challenge was to autonomously navigate through **14 target waypoints** while:  
- Minimizing **energy consumption**.  
- Ensuring **collision-free** navigation.  
- Maintaining **safe and legal driving behavior**.  

![Alt text](Shell Paper.drawio)
---

## ğŸ“‚ Project Structure  

```
project/
â”‚
â”œâ”€â”€ custom_msg/                # Custom ROS message definitions
â”‚   â”œâ”€â”€ msg/                   # Object info, dimensions, traffic lights, perception outputs
â”‚   â”œâ”€â”€ include/custom_msg/    # Message headers
â”‚   â”œâ”€â”€ src/                   # Supporting C++ code (if any)
â”‚   â”œâ”€â”€ package.xml
â”‚   â””â”€â”€ CMakeLists.txt
â”‚
â”œâ”€â”€ shell_simulation/          # Core simulation and stack implementation
â”‚   â”œâ”€â”€ src/shell_simulation/  # Core Python modules
â”‚   â”‚   â”œâ”€â”€ kalman_filter.py   # Multi-object tracking with Kalman filter + Hungarian algorithm
â”‚   â”‚   â”œâ”€â”€ lidar_utilities.py # Classical 3D LiDAR preprocessing, segmentation, clustering
â”‚   â”‚   â”œâ”€â”€ controller.py      # Lateral (Pure Pursuit) & Longitudinal (MPC/Adaptive PID) control
â”‚   â”‚   â””â”€â”€ graph.py           # Utilities for TSP (Dynamic Programming)
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                  # Precomputed CSV files
â”‚   â”‚   â”œâ”€â”€ trajectory.csv     # Global path waypoints
â”‚   â”‚   â”œâ”€â”€ centroids.csv      # Clustered LiDAR centroids
â”‚   â”‚   â””â”€â”€ traffic_lights_info.csv # Traffic light locations & IDs
â”‚   â”‚
â”‚   â”œâ”€â”€ scripts/               # ROS Nodes
â”‚   â”‚   â”œâ”€â”€ lidar_node.py          # LiDAR-based 3D object detection
â”‚   â”‚   â”œâ”€â”€ planner_perception_node.py # Fusion of LiDAR & camera detections
â”‚   â”‚   â”œâ”€â”€ behavior_planner_node.py   # Mode selection (stop, proceed, follow, maneuver)
â”‚   â”‚   â”œâ”€â”€ path_tracker_node.py       # Path tracking & Frenet planner integration
â”‚   â”‚   â”œâ”€â”€ controller_node.py         # Interface to low-level control
â”‚   â”‚   â””â”€â”€ logger_node.py             # Logging system states & results
â”‚   â”‚
â”‚   â”œâ”€â”€ launch/                # ROS launch files
â”‚   â”‚   â”œâ”€â”€ shell_simulation.launch
â”‚   â”‚   â”œâ”€â”€ path_tracker_controller.launch
â”‚   â”‚   â””â”€â”€ test.launch
â”‚   â”‚
â”‚   â”œâ”€â”€ resource/              # ROS package resource markers
â”‚   â”œâ”€â”€ package.xml
â”‚   â”œâ”€â”€ setup.py
â”‚   â””â”€â”€ CMakeLists.txt
â”‚
â””â”€â”€ ...
```

---

## ğŸ”‘ System Overview  

### 1. Global Planning  
- **Traveling Salesman Problem (TSP):** Solved with **Dynamic Programming**, ensuring the most energy-efficient order of visiting all 14 waypoints.  
- Planned path stored in **trajectory.csv** for downstream modules.  

### 2. Perception  
- **3D LiDAR (Velodyne VLP-16):**  
  - Preprocessing: voxel grid downsampling, noise filtering, ground plane removal.  
  - Segmentation: Euclidean clustering/DBSCAN.  
  - Feature extraction: geometric + statistical features per object.  
- **Camera (RGB-D):** 2D object detection (YOLOv11 Nano).  
- **Traffic Lights:** YOLO detection + OpenCV color classification.  
- **Sensor Fusion:** Combines LiDAR 3D geometry with camera semantic classification.  
- **Multi-object Tracking:** Kalman Filter + Hungarian algorithm for consistent IDs.  

### 3. Behavior Planning  
Evaluates ego state and perception to select **driving mode**:  
- **Stop:** When red light or lead vehicle stops (outputs stopping distance).  
- **Proceed:** Road is clear â†’ follow global path.  
- **Follow:** Adaptive Cruise Control (ACC) with relative speed + distance.  
- **Maneuver:** Safe overtaking using Frenet planner.  

The **Frenet planner** is activated only during overtakes to save computation, optimizing both **safety cost** and **energy cost**.  

### 4. Control  
- **Lateral Control:** Adaptive Pure Pursuit with variable lookahead.  
- **Longitudinal Control:** MPC or Adaptive PID for smooth, energy-efficient speed regulation.  

---

##  Key Highlights  
- Achieved **2nd place globally** with this stack.  
- Strong balance of **classical perception algorithms** and **lightweight planning/control** methods.  
- Focused on **energy efficiency** while preserving safety.  
[See results](https://www.shellecomarathon.com/2025-programme/autonomous-programming-competition.html)

---

## âš™ï¸ Build and Run Instructions (Catkin Tools)  

This repository is designed to be built within a **ROS Catkin workspace**. Place the repo inside `src/` of your catkin workspace, then follow these steps:  

### 1. Initialize catkin workspace  
```bash
catkin init
```

### 2. Configure to use install space  
```bash
catkin config --install
```

### 3. Set build options  
```bash
catkin config --cmake-args -DCMAKE_BUILD_TYPE=RelWithDebInfo -DSETUPTOOLS_DEB_LAYOUT=OFF
```

### 4. Install dependencies (from workspace root)  
```bash
rosdep update
rosdep install . -q -y --from-paths -i
```

### 5. Build the workspace  
```bash
catkin build
```

### 6. Source installed environment  
```bash
source install/setup.bash
```

### 7. Run the main launch file  
```bash
roslaunch shell_simulation shell_simulation.launch
```

---

## ğŸ›  Alternative Build (catkin_make)  

If you are using **catkin_make**:  

```bash
catkin_make
source devel/setup.bash
roslaunch shell_simulation shell_simulation.launch
```

---

## ğŸ”— External Dependencies  

Before running, ensure you have the Shell Eco-marathon CARLA + ROS bridge docker environment installed:  

- [SEM-APC Student Docker Environment](https://github.com/swri-robotics/sem-apc-student-docker-environment)  
- [SEM-APC Example Project](https://github.com/swri-robotics/sem-apc-example-project)  

### Requirements  
- **Ubuntu 22.04 (preferred)**  
- Docker environment above installed and running  
- `carla_config.yaml` must be edited to match the one provided in this repository  

### Launch Order  
1. Start the **simulation environment** (CARLA + shell ROS bridge):  
```bash
roslaunch carla_shell_bridge main.launch
```  

2. Run this software stack:  
```bash
roslaunch shell_simulation shell_simulation.launch
```  

---

## ğŸ“Œ Notes  
- Ensure that `carla_config.yaml` matches the configuration in this repo before starting.  
- Always launch the CARLA bridge before starting simulation nodes.  
